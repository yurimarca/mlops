{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88360f6-960c-42d5-85fc-9f4ba22dd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f751b47b-66c8-42ef-804f-9c7fea21dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d66e5b-566f-4acf-a38f-02c256756b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.12.0-py2.py3-none-any.whl (390 kB)\n",
      "\u001b[K     |████████████████████████████████| 390 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: imagehash==4.3.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (4.3.1)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (0.12.3)\n",
      "Requirement already satisfied: scipy<1.14,>=1.4.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (1.10.1)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (6.0.2)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (0.1.12)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (1.4)\n",
      "Requirement already satisfied: numpy<2.2,>=1.16.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (2.32.3)\n",
      "Requirement already satisfied: matplotlib<3.10,>=3.5 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (3.7.3)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (0.14.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (3.1.4)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (1.2.3)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (0.11.1)\n",
      "Requirement already satisfied: pydantic>=2 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (2.8.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from ydata-profiling) (4.67.0)\n",
      "Requirement already satisfied: pillow in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from imagehash==4.3.1->ydata-profiling) (10.3.0)\n",
      "Requirement already satisfied: PyWavelets in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
      "Collecting dacite>=1.8\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (4.53.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (2.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (3.1.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib<3.10,>=3.5->ydata-profiling) (3.21.0)\n",
      "Collecting numba<1,>=0.56.0\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from numba<1,>=0.56.0->ydata-profiling) (8.5.0)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 43.6 MB 825 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2024.2)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from pydantic>=2->ydata-profiling) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from pydantic>=2->ydata-profiling) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib<3.10,>=3.5->ydata-profiling) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patsy>=0.5.4 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.6)\n",
      "Collecting typeguard<5,>=3\n",
      "  Downloading typeguard-4.4.0-py3-none-any.whl (35 kB)\n",
      "Collecting visions[type_image_path]<0.7.7,>=0.7.5\n",
      "  Downloading visions-0.7.6-py3-none-any.whl (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (24.2.0)\n",
      "Collecting pandas!=1.4.0,<3,>1.1\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 893 kB/s eta 0:00:01    |████                            | 1.6 MB 498 kB/s eta 0:00:22     |█████████████████████████▌      | 9.8 MB 795 kB/s eta 0:00:04\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wordcloud>=1.9.3\n",
      "  Downloading wordcloud-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (520 kB)\n",
      "\u001b[K     |████████████████████████████████| 520 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas, visions, llvmlite, wordcloud, typeguard, numba, dacite, ydata-profiling\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.3\n",
      "    Uninstalling pandas-1.2.3:\n",
      "      Successfully uninstalled pandas-1.2.3\n",
      "  Attempting uninstall: visions\n",
      "    Found existing installation: visions 0.7.4\n",
      "    Uninstalling visions-0.7.4:\n",
      "      Successfully uninstalled visions-0.7.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires visions[type_image_path]==0.7.4, but you have visions 0.7.6 which is incompatible.\u001b[0m\n",
      "Successfully installed dacite-1.8.1 llvmlite-0.41.1 numba-0.58.1 pandas-2.0.3 typeguard-4.4.0 tzdata-2024.2 visions-0.7.6 wordcloud-1.9.4 ydata-profiling-4.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63edc8e2-91ea-4e95-a14a-d2105f400817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydata_profiling as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7106a46-281b-4bd7-91d3-8188341e8153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myurimarca-ai\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">pious-mountain-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/yurimarca-ai/exercise_4\" target=\"_blank\">https://wandb.ai/yurimarca-ai/exercise_4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/yurimarca-ai/exercise_4/runs/00abrqbm\" target=\"_blank\">https://wandb.ai/yurimarca-ai/exercise_4/runs/00abrqbm</a><br/>\n",
       "                Run data is saved locally in <code>/home/ymarca/Code/mlops/reproducible_model_workflow/2_data_exploration_and_preparation/exercises/4_eda/my-solution/wandb/run-20241119_211124-00abrqbm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a run for our project; name automatically generated\n",
    "run = wandb.init(\n",
    "  project=\"exercise_4\",\n",
    "  save_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b966fcfe-6df9-486a-9473-87133239f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact(\"genres_mod.parquet:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf85db86",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - No module named 'pandas.core.arrays._arrow_utils'\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages/pandas/io/parquet.py:458\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[1;32m    430\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    437\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    path : str, path object or file-like object\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m        String, path object (implementing ``os.PathLike[str]``), or file-like\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m        object implementing a binary ``read()`` function.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m        The string could be a URL. Valid URL schemes include http, ftp, s3,\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m        gs, and file. For file URLs, a host is expected. A local file could be:\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m        ``file://localhost/path/to/table.parquet``.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m        A file URL can also be a path to a directory that contains multiple\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m        partitioned parquet files. Both pyarrow and fastparquet support\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m        paths to directories as well as file URLs. A directory path could be:\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        ``file://localhost/path/to/tables`` or ``s3://bucket/partition_dir``.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto'\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m        Parquet library to use. If 'auto', then the option\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m        ``io.parquet.engine`` is used. The default ``io.parquet.engine``\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m        behavior is to try 'pyarrow', falling back to 'fastparquet' if\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m        'pyarrow' is unavailable.\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m \u001b[38;5;124;03m    columns : list, default=None\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m        If not None, only these columns will be read from the file.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    {storage_options}\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    use_nullable_dtypes : bool, default False\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m        If True, use dtypes that use ``pd.NA`` as missing value indicator\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m        for the resulting DataFrame. (only applicable for the ``pyarrow``\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m        engine)\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m        As new dtypes are added that support ``pd.NA`` in the future, the\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03m        output with this option will change to use those dtypes.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m        Note: this is an experimental option, and behaviour (e.g. additional\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m        support dtypes) may change without notice.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m        .. deprecated:: 2.0\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m    dtype_backend : {{\"numpy_nullable\", \"pyarrow\"}}, defaults to NumPy backed DataFrames\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m        Which dtype_backend to use, e.g. whether a DataFrame should have NumPy\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m        arrays, nullable dtypes are used for all dtypes that have a nullable\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m        implementation when \"numpy_nullable\" is set, pyarrow is used for all\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m        dtypes if \"pyarrow\" is set.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m        The dtype_backends are still experimential.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 2.0\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    **kwargs\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m        Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03m    DataFrame\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages/pandas/io/parquet.py:36\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     32\u001b[0m from pandas.core.shared_docs import _shared_docs\n\u001b[1;32m     33\u001b[0m from pandas.util.version import Version\n\u001b[1;32m     35\u001b[0m from pandas.io.common import (\n\u001b[0;32m---> 36\u001b[0m     IOHandles,\n\u001b[1;32m     37\u001b[0m     get_handle,\n\u001b[1;32m     38\u001b[0m     is_fsspec_url,\n\u001b[1;32m     39\u001b[0m     is_url,\n\u001b[1;32m     40\u001b[0m     stringify_path,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     44\u001b[0m def get_engine(engine: str) -> BaseImpl:\n\u001b[1;32m     45\u001b[0m     \"\"\"return our implementation\"\"\"\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - No module named 'pandas.core.arrays._arrow_utils'\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(artifact.file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc59a201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (2.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.14 in /home/ymarca/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages (from pyarrow) (1.24.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1656bc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - No module named 'pandas.core.arrays._arrow_utils'\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages/pandas/io/parquet.py:458\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[1;32m    430\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    437\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    path : str, path object or file-like object\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m        String, path object (implementing ``os.PathLike[str]``), or file-like\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m        object implementing a binary ``read()`` function.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m        The string could be a URL. Valid URL schemes include http, ftp, s3,\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m        gs, and file. For file URLs, a host is expected. A local file could be:\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m        ``file://localhost/path/to/table.parquet``.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m        A file URL can also be a path to a directory that contains multiple\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m        partitioned parquet files. Both pyarrow and fastparquet support\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m        paths to directories as well as file URLs. A directory path could be:\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        ``file://localhost/path/to/tables`` or ``s3://bucket/partition_dir``.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto'\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m        Parquet library to use. If 'auto', then the option\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m        ``io.parquet.engine`` is used. The default ``io.parquet.engine``\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m        behavior is to try 'pyarrow', falling back to 'fastparquet' if\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m        'pyarrow' is unavailable.\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m \u001b[38;5;124;03m    columns : list, default=None\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m        If not None, only these columns will be read from the file.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    {storage_options}\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    use_nullable_dtypes : bool, default False\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m        If True, use dtypes that use ``pd.NA`` as missing value indicator\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m        for the resulting DataFrame. (only applicable for the ``pyarrow``\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m        engine)\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m        As new dtypes are added that support ``pd.NA`` in the future, the\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03m        output with this option will change to use those dtypes.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m        Note: this is an experimental option, and behaviour (e.g. additional\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m        support dtypes) may change without notice.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m        .. deprecated:: 2.0\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m    dtype_backend : {{\"numpy_nullable\", \"pyarrow\"}}, defaults to NumPy backed DataFrames\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m        Which dtype_backend to use, e.g. whether a DataFrame should have NumPy\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m        arrays, nullable dtypes are used for all dtypes that have a nullable\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m        implementation when \"numpy_nullable\" is set, pyarrow is used for all\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m        dtypes if \"pyarrow\" is set.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m        The dtype_backends are still experimential.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 2.0\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    **kwargs\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m        Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03m    DataFrame\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlflow-5b75f31d43ca31c6ba5483260979c87b36fe8609/lib/python3.8/site-packages/pandas/io/parquet.py:36\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     32\u001b[0m from pandas.core.shared_docs import _shared_docs\n\u001b[1;32m     33\u001b[0m from pandas.util.version import Version\n\u001b[1;32m     35\u001b[0m from pandas.io.common import (\n\u001b[0;32m---> 36\u001b[0m     IOHandles,\n\u001b[1;32m     37\u001b[0m     get_handle,\n\u001b[1;32m     38\u001b[0m     is_fsspec_url,\n\u001b[1;32m     39\u001b[0m     is_url,\n\u001b[1;32m     40\u001b[0m     stringify_path,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     44\u001b[0m def get_engine(engine: str) -> BaseImpl:\n\u001b[1;32m     45\u001b[0m     \"\"\"return our implementation\"\"\"\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - No module named 'pandas.core.arrays._arrow_utils'\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(artifact.file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74cbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
